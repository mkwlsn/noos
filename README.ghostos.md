# noos

**Universal symbolic memory compiler for ghostOS** â€” transforms any source into semantic chunks with rich frontmatter for the symbolic memory stack.

## ğŸ§  ghostOS Memory Stack

```
ğŸ” Sources â†’ ğŸ§  noos â†’ ğŸ§¼ eidetic-reduce â†’ ğŸ‘» mneme â†’ ğŸ›ï¸ ghostvault
Raw Content  Compiler   Validation       Retrieval    Storage
```

**noos** is the foundational chunking engine that transforms raw content into symbolic memory units that ghostOS rituals can query, validate, and retrieve.

## ğŸ—ï¸ Architecture

**4-Stage Pipeline:**

```
ğŸ“¡ SCRAPE â†’ ğŸ§¼ CLEAN â†’ âš›ï¸ CHUNK â†’ ğŸ©¹ HEAL
Raw HTML    Markdown    Atomic     Memory
                       Concepts   Substrate
```

**Compiler Pattern:**

```
noos/
â”œâ”€â”€ compilers/          # Source-specific compilers
â”‚   â”œâ”€â”€ figma/         # Figma documentation compiler
â”‚   â””â”€â”€ [web/, docs/]  # Future: any source
â”œâ”€â”€ core/              # Universal processing engine
â”‚   â”œâ”€â”€ clean-html.js # HTML â†’ versioned markdown
â”‚   â””â”€â”€ chunk-md-by-heading.js # Symbolic chunking
â”œâ”€â”€ integrations/      # ghostOS memory substrate healing
â”‚   â””â”€â”€ eidetic-prep.js # YAML repair & schema normalization
â””â”€â”€ schemas/           # Memory schemas
```

**Universal Output:**

- âœ… **Semantic chunks** with heading-based boundaries
- âœ… **Rich frontmatter** (chunk_type, tags, sibling_chunks)
- âœ… **Symbolic metadata** (source, content_hash, token_count)
- âœ… **eidetic-reduce ready** for validation rituals
- âœ… **mneme compatible** for retrieval queries

---

## ğŸš€ Quick Start

### Full Pipeline (Recommended)

```bash
npm run figdocs  # Complete end-to-end: scrape â†’ clean â†’ chunk
```

### Fresh Ingest Workflow

```bash
# Clean slate (delete all previous outputs)
rm -rf output/raw output/clean output/chunks

# Full fresh compilation
npm run figdocs

# Memory substrate healing
npm run eidetic-prep  # Run this after a successful pull and chunk pass
```

### Individual Stages (Development/Debugging)

```bash
# Stage 1: Source compilation
node compilers/figma/scrape-all.js
# â†’ Scrapes Figma docs handling React hydration, pagination, lazy loading
# â†’ Outputs: Raw HTML files in output/raw/

# Stage 2: Content cleaning
node core/clean-html.js
# â†’ Converts HTML to markdown with rich frontmatter and metadata
# â†’ Outputs: Versioned markdown in output/clean/YYYY-MM-DD/

# Stage 3: Symbolic chunking
node core/chunk-md-by-heading.js
# â†’ Creates semantic chunks with sibling navigation and classification
# â†’ Outputs: noos chunks ready for ghostOS in output/chunks/YYYY-MM-DD/

# Stage 4: Memory substrate healing
node integrations/eidetic-prep.js
# â†’ YAML frontmatter repair and schema normalization
# â†’ Fixes syntax errors and ensures ghostOS compatibility
```

### Quality Monitoring

```bash
# Check processing status
grep "[ERROR]" output/chunks/*/chunk-errors.log
grep "SUCCESS" output/chunks/*/chunk-manifest.json

# Memory integrity analysis
wc -l output/chunks/*/chunk-manifest.json  # Total chunks processed
ls output/chunks/*/ | grep ".md$" | wc -l   # Successful chunks created
```

### ghostOS Integration

```bash
npm run deploy-vault    # Sync chunks to ghostvault
npm run eidetic-prep    # Memory substrate healing ritual
```

---

## ğŸ“Š Symbolic Output

**Chunk Structure:**

```yaml
---
title: insertCharacters
slug: textnode-insertcharacters
chunk_type: method
sibling_chunks: ["textnode-deletecharacters", "textnode-getstyledtextsegments"]
tags: []
parent_file: textnode.md
content_hash: a1b2c3d4e5f6
token_count: 340
source_url: https://www.figma.com/plugin-docs/api/TextNode/
---
# insertCharacters(start, characters, style?)

Inserts characters into the text node at the specified position...
```

**Versioned Output:**

```
output/
â”œâ”€â”€ raw/               # Source material (gitignored)
â”œâ”€â”€ clean/             # Cleaned markdown
â”‚   â””â”€â”€ 2025-06-26/   # Versioned runs
â””â”€â”€ chunks/            # Symbolic memory chunks
    â””â”€â”€ 2025-06-26/   # Ready for ghostOS rituals
```

---

## ğŸ¯ ghostOS Integration

**Memory Validation:**

- Chunks formatted for `eidetic-reduce` ritual
- Deduplication and drift detection ready
- Quality metrics and error logging

**Retrieval Compatibility:**

- `mneme` daemon can query by chunk_type, tags, source
- Sibling chunk navigation for semantic exploration
- Cross-source concept linking preparation

**Ritual Support:**

- Future `ghost search`, `ghost trace`, `ghost surf` commands
- Symbolic memory operations on clean, structured chunks
- Integration with broader ghostOS memory stack

---

## ğŸ”§ Compiler Development

**Adding New Sources:**

1. Create `compilers/[source]/` directory
2. Implement source-specific scraping/extraction
3. Output to standard format for `core/` processing
4. Universal chunking engine handles the rest

**Core Engine:**

- `core/clean-html.js` â€” HTML â†’ markdown normalization
- `core/chunk-md-by-heading.js` â€” Semantic boundary detection
- Universal frontmatter generation and metadata extraction

---

## ğŸ“ˆ Current Status

**Figma Compiler:** âœ… Complete (2,819 chunks, 99.96% integrity)  
**Core Engine:** âœ… Production-ready with comprehensive error handling  
**Memory Substrate Healing:** âœ… YAML repair & schema normalization  
**ghostOS Integration:** âœ… eidetic-reduce ready, mneme compatible  
**Future Compilers:** ğŸ“‹ Web, docs, notes, conversations

**Performance Metrics:**

- **2,819 functional chunks** from comprehensive Figma documentation
- **99.96% memory integrity** (2,819/2,820 successful)
- **Comprehensive healing**: 5,595 YAML repair interventions
- **Versioned corpus**: Full diff capability between runs

Built as the **symbolic memory foundation** for the ghostOS cognition system.

---

## ğŸ“„ License

This repository is not currently open source. All rights reserved.  
For licensing inquiries, contact [mkwlsn@github.com].
